{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "a=time.perf_counter()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import datetime, date \n",
    "from lightfm.data import Dataset\n",
    "from lightfm import LightFM\n",
    "from lightfm import cross_validation\n",
    "from lightfm.evaluation import precision_at_k\n",
    "from lightfm.evaluation import auc_score\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "path='./data_juin/'\n",
    "df_user=pd.read_csv(path + 'user.csv',sep=',')\n",
    "df_favorite=pd.read_csv(path + 'favorite.csv',sep=',')\n",
    "df_visit=pd.read_csv(path + 'visit.csv',sep=',')\n",
    "df_place=pd.read_csv(path + 'place.csv',sep=',',encoding='latin-1')\n",
    "review=pd.read_csv(path + 'review.csv',sep=',',encoding='latin-1')\n",
    "df_place_place_type=pd.read_csv(path + 'place_place_type.csv',sep=',')\n",
    "place_type=pd.read_csv(path + 'place_type.csv',sep=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_int_id(dataframe, id_col_name):\n",
    "    \"\"\"\n",
    "    Generate unique integer id for users, questions and answers\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    dataframe: Dataframe\n",
    "        Pandas Dataframe for Users or Q&A. \n",
    "    id_col_name : String \n",
    "        New integer id's column name.\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    Dataframe\n",
    "        Updated dataframe containing new id column \n",
    "    \"\"\"\n",
    "    new_dataframe=dataframe.assign(\n",
    "        int_id_col_name=np.arange(len(dataframe))\n",
    "        ).reset_index(drop=True)\n",
    "    return new_dataframe.rename(columns={'int_id_col_name': id_col_name})\n",
    "\n",
    "#drop columns if they have to many na \n",
    "\n",
    "def drop_columns_na(dataframe,pourcentna):\n",
    "    for i in dataframe.columns:\n",
    "        pourcent=(dataframe[i].isna().sum()/dataframe[i].isna().count())\n",
    "        if(pourcentna<pourcent):\n",
    "            dataframe.drop(i,axis=1,inplace=True)\n",
    "    return dataframe\n",
    "\n",
    "\n",
    "def create_features(dataframe, features_name, id_col_name):\n",
    "    \"\"\"\n",
    "    Generate features that will be ready for feeding into lightfm\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    dataframe: Dataframe\n",
    "        Pandas Dataframe which contains features\n",
    "    features_name : List\n",
    "        List of feature columns name avaiable in dataframe\n",
    "    id_col_name: String\n",
    "        Column name which contains id of the question or\n",
    "        answer that the features will map to.\n",
    "        There are two possible values for this variable.\n",
    "        1. questions_id_num\n",
    "        2. professionals_id_num\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    Pandas Series\n",
    "        A pandas series containing process features\n",
    "        that are ready for feed into lightfm.\n",
    "        The format of each value\n",
    "        will be (user_id, ['feature_1', 'feature_2', 'feature_3'])\n",
    "        Ex. -> (1, ['military', 'army', '5'])\n",
    "    \"\"\"\n",
    "\n",
    "    features = dataframe[features_name].apply(\n",
    "        lambda x: ','.join(x.map(str)), axis=1)\n",
    "    features = features.str.split(',')\n",
    "    features = list(zip(dataframe[id_col_name], features))\n",
    "    return features\n",
    "\n",
    "\n",
    "\n",
    "def generate_feature_list(dataframe, features_name):\n",
    "    \"\"\"\n",
    "    Generate features list for mapping \n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    dataframe: Dataframe\n",
    "        Pandas Dataframe for Users or Q&A. \n",
    "    features_name : List\n",
    "        List of feature columns name avaiable in dataframe. \n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    List of all features for mapping \n",
    "    \"\"\"\n",
    "    features = dataframe[features_name].apply(\n",
    "        lambda x: ','.join(x.map(str)), axis=1)\n",
    "    features = features.str.split(',')\n",
    "    features = features.apply(pd.Series).stack().reset_index(drop=True)\n",
    "    return features\n",
    "\n",
    "\n",
    "def calculate_auc_score(lightfm_model, interactions_matrix, \n",
    "                        question_features, professional_features): \n",
    "    \"\"\"\n",
    "    Measure the ROC AUC metric for a model. \n",
    "    A perfect score is 1.0.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    lightfm_model: LightFM model \n",
    "        A fitted lightfm model \n",
    "    interactions_matrix : \n",
    "        A lightfm interactions matrix \n",
    "    question_features, professional_features: \n",
    "        Lightfm features \n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    String containing AUC score \n",
    "    \"\"\"\n",
    "    score = auc_score( \n",
    "        lightfm_model, interactions_matrix, \n",
    "        item_features=question_features, \n",
    "        user_features=professional_features, \n",
    "        num_threads=4).mean()\n",
    "    return score\n",
    "\n",
    "#simple fonction pour avoir user_id_light d'un user par sont user_id    \n",
    "def get_user_id_light_from_user_id(user_id):\n",
    "    user_id_light=user.loc[user['user_id']==user_id].user_id_light.item()\n",
    "    return user_id_light\n",
    "\n",
    "\n",
    "def drop_place_deja_connue(df_prediction,user_id):\n",
    "    \"\"\"\n",
    "    cette fonction verifie qu'elle bar un user a deja en favoris ou en visit \n",
    "    et les exclue du resultas =\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    df_prediction: prediction des bar trouvé par le modele \n",
    "\n",
    "    user_id: id provenant de schloukmap pour le user  \n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    la liste des prediction propre\n",
    "    \n",
    "    \n",
    "    \"\"\"\n",
    "    favorie = df_favorite[['place_id','user_id']]\n",
    "    visit = df_visit[['place_id','user_id']]\n",
    "    fav_vis = pd.concat([favorie,visit])\n",
    "    #on recupere tous les couple user_id place_id des visit et favori de tous les user \n",
    "\n",
    "\n",
    "    df_do_not_recomend=fav_vis.drop_duplicates()#on enleve les doublons\n",
    "\n",
    "    user_already_visit_favori = df_do_not_recomend[df_do_not_recomend['user_id']==user_id]\n",
    "    #isole la liste des bar concernant le user \n",
    "\n",
    "    df_prediction = df_prediction[~df_prediction.id.isin(user_already_visit_favori.place_id)]\n",
    "    #suprime les bar qui apparaise des deux coté\n",
    "    return df_prediction\n",
    "\n",
    "\n",
    "\n",
    "def recommandation_for_user_by_city(user_id,city_id):\n",
    "    \"\"\"\n",
    "    permet de faire une recommendation a un user en la limitant a la ville ou\n",
    "    il ce situe et en triant les bar fermé ou non disponible et aussie ceux deja visité\n",
    "    par ce dernier\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    id_user: user id for lightfm\n",
    "\n",
    "    city_id: id de la ville \n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    dataframe des place trié par odre de pertinance pour l'utilisateur\n",
    "    \n",
    "    \n",
    "    \"\"\"\n",
    "    #on convertie le user_id utilisé par schlouk map en le light_id utilisé par le modele\n",
    "    light_fm_id=get_user_id_light_from_user_id(user_id)\n",
    "    user = user_id_map[light_fm_id]#donne la possition dans le mapping de l'user concerné\n",
    "    list_prediction=model.predict(user, np.arange(n_items)) #donne la liste des id de bar \n",
    "    #a recommendé en renvoyant dans l'ordre chaque bar et sont score \n",
    "    \n",
    "    #on crée un dataframe de nos prediction\n",
    "    df_prediction = pd.DataFrame(list_prediction, columns=['score'])\n",
    "    #reset de l'index pour le merge car ce dernier correspond au place_id_light\n",
    "    df_prediction=df_prediction.reset_index()\n",
    "    #on merge nos prediction avec les bar selont l'id light pour retrouve les infos des bars\n",
    "    df_prediction=df_prediction.merge(\n",
    "        place,how='inner',left_on='index',right_on='place_id_light'\n",
    "    )\n",
    "    #on enleve les bar fermé \n",
    "    df_prediction = df_prediction.drop(df_prediction[df_prediction.is_closed==1].index)\n",
    "    df_prediction = df_prediction.drop(df_prediction[df_prediction.is_published == 0].index)\n",
    "    #on filtre sur la ville ou ce trouve le user\n",
    "    df_prediction = df_prediction.drop(df_prediction[df_prediction.city_id != city_id].index)\n",
    "    #on tri en fonction du score les bar pour voire les qu'elle sont les plus adapté au user\n",
    "\n",
    "    df_prediction = drop_place_deja_connue(df_prediction,user_id) \n",
    "\n",
    "    df_prediction=df_prediction.sort_values(by='score',ascending=False)\n",
    "    \n",
    "    return df_prediction\n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "on import nos user qui sont les persone a qui on doit recommander une place (bar)\n",
    "on drop les columns sans intérais pour nous comme la date de création la dernier mise a jour ect \n",
    "et on leur génere un id speciale qui servira seulement pour notre model car on a besoin d'avoir des id unique par user qui commence a 0 et sont consecutif jusqu'au dernier (comme certains user de la db ne sont pas des user rélle mais ajouté par l'equipe de schlouk map pour diverse raisson on drop les personne sans firebase uid )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/_h/1j2lys1s0g344s_0q1rbvvt00000gn/T/ipykernel_4608/3228095920.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  user.rename(columns={'id':'user_id'},inplace=True)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>firebase_uid</th>\n",
       "      <th>user_id_light</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>31280</td>\n",
       "      <td>zzzZClWPVSQ22uT2SqQqQQfSPon2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>33287</td>\n",
       "      <td>ZZzYwUhcuTN7WUlKTNVJ0El7Gz83</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>29924</td>\n",
       "      <td>zZZMZBYZKXP3ClI83zvehUXXXsp2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11040</td>\n",
       "      <td>ZzZ4AF9HvmaWo3ssjW3vAmgEacj1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>32661</td>\n",
       "      <td>zzxJ4S3MRxVDxcZ71UWQv7qfUG92</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45475</th>\n",
       "      <td>16737</td>\n",
       "      <td>00KjtvKZG3ahSKyCt3AyRyTAesG3</td>\n",
       "      <td>45475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45476</th>\n",
       "      <td>31535</td>\n",
       "      <td>00FyNO18CYSV8sLQgbpKH0kQRmP2</td>\n",
       "      <td>45476</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45477</th>\n",
       "      <td>39028</td>\n",
       "      <td>00e24es9Rse3DSsByF9kgR8TPHD3</td>\n",
       "      <td>45477</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45478</th>\n",
       "      <td>40048</td>\n",
       "      <td>00AUdltem0aniOvFw8iRpCgO9Fo1</td>\n",
       "      <td>45478</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45479</th>\n",
       "      <td>26641</td>\n",
       "      <td>005zUjouOgaUICI0gNaTOYAdX082</td>\n",
       "      <td>45479</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>45480 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       user_id                  firebase_uid  user_id_light\n",
       "0        31280  zzzZClWPVSQ22uT2SqQqQQfSPon2              0\n",
       "1        33287  ZZzYwUhcuTN7WUlKTNVJ0El7Gz83              1\n",
       "2        29924  zZZMZBYZKXP3ClI83zvehUXXXsp2              2\n",
       "3        11040  ZzZ4AF9HvmaWo3ssjW3vAmgEacj1              3\n",
       "4        32661  zzxJ4S3MRxVDxcZ71UWQv7qfUG92              4\n",
       "...        ...                           ...            ...\n",
       "45475    16737  00KjtvKZG3ahSKyCt3AyRyTAesG3          45475\n",
       "45476    31535  00FyNO18CYSV8sLQgbpKH0kQRmP2          45476\n",
       "45477    39028  00e24es9Rse3DSsByF9kgR8TPHD3          45477\n",
       "45478    40048  00AUdltem0aniOvFw8iRpCgO9Fo1          45478\n",
       "45479    26641  005zUjouOgaUICI0gNaTOYAdX082          45479\n",
       "\n",
       "[45480 rows x 3 columns]"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user=df_user\n",
    "# user=user.drop(['created_at','updated_at'],axis=1)\n",
    "user=user.dropna(subset=['firebase_uid'])\n",
    "user.rename(columns={'id':'user_id'},inplace=True)\n",
    "user = generate_int_id(user,\"user_id_light\") # genere des id unique, consecutif de zero a la dernier personne indispensable pour lightfm\n",
    "user"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "on récupere seulement les infos qui pourrais nous etre utile pour chaque bar et comme pour les user on leur crée un lightfm id qui servira au mapping \n",
    "on modifie aussi le type pour evité certaine erreur au moment des merge "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "place = df_place[['id','is_closed','is_published','has_offers','has_food','has_terrace','slug','city_id']]\n",
    "place=place.astype(object)\n",
    "place=generate_int_id(place,\"place_id_light\") # genere des id unique,consecutif de zero a la dernier personne indispensable pour lightfm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "on cherche a savoir qu'elle utilisateur on un favoris ou un lien avec au moins un  bar et on va créé une rellation pour les user qui n'en non aucun actuellement \n",
    "\n",
    "pour cela on recupere la liste des user dans favoris et on drop les doublon \n",
    "cela nous permet de recupere avec un merge qui n'a aucun favoris \n",
    "\n",
    "puis on fais un merge entre tous nos user et ceux posssedant une favoris, on ajoutant un indicateur ce qui va permetre d'isolé les user ne possedant pas de favoris car il auront l'indicateur 'left_only' la ou les autre on 'both'\n",
    "\n",
    "on a donc une liste et un df qui serviront un peut plus tard "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "# \n",
    "qui_a_un_favoris=df_favorite.drop_duplicates(subset='user_id')\n",
    "qui_a_un_favoris=qui_a_un_favoris['user_id'] #liste des user ayant au moins un favoris\n",
    "\n",
    "\n",
    "user_without_favori=user.merge(\n",
    "    qui_a_un_favoris,how='outer',on='user_id',indicator=True\n",
    ")#on merge tous nos user avec ceux ayant un favoris en diferentiens ceux ayant les deux par l'indiacteur \n",
    "\n",
    "indexNames=user_without_favori[user_without_favori['_merge'] == 'both'].index\n",
    "user_without_favori.drop(indexNames , inplace=True) # on drop ceux ayant deja un favoris \n",
    "\n",
    "list_user_without_favoris=user_without_favori['user_id']#format list des user sans favoris\n",
    "df_user_without_favoris=user_without_favori[['user_id']]#format dataframe des user sans favoris\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "pour des soucis explicité en detaille dans notre rapport il faut que tous nos user soit liée a un bar (par une visite,favoris ou review idéalement) mais certains user n'utilise pas ces fonctionalité la dans l'app (choses qui va changer avec le temps)\n",
    "\n",
    "donc grace a la list des user sans favoris crée juste avant on crée au moins un lien entre chaque user et bar de facons aleatoire (user n'ayant pas de rellation evidement et comme le modele ce rentraineras regulierement cette aleatoire ne serra que temporaire et cela ne derange pas schlouk map d'un point de vue buisness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>place_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>31280</td>\n",
       "      <td>5761</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>33287</td>\n",
       "      <td>4663</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>29924</td>\n",
       "      <td>5446</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11040</td>\n",
       "      <td>5216</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>32661</td>\n",
       "      <td>3799</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40030</th>\n",
       "      <td>8261</td>\n",
       "      <td>7028</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40031</th>\n",
       "      <td>16737</td>\n",
       "      <td>6857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40032</th>\n",
       "      <td>39028</td>\n",
       "      <td>4365</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40033</th>\n",
       "      <td>40048</td>\n",
       "      <td>5970</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40034</th>\n",
       "      <td>26641</td>\n",
       "      <td>6902</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>40035 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       user_id  place_id\n",
       "0        31280      5761\n",
       "1        33287      4663\n",
       "2        29924      5446\n",
       "3        11040      5216\n",
       "4        32661      3799\n",
       "...        ...       ...\n",
       "40030     8261      7028\n",
       "40031    16737      6857\n",
       "40032    39028      4365\n",
       "40033    40048      5970\n",
       "40034    26641      6902\n",
       "\n",
       "[40035 rows x 2 columns]"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "place_id_list=place['id']#on recupere l'id des bar\n",
    "\n",
    "liste_user=[]\n",
    "for i in  list_user_without_favoris: #creation d'une liste avec juste les id des user sans\n",
    "    liste_user.append(i)\n",
    "\n",
    "liste_place=[]\n",
    "for i in range(len(liste_user)): #creation d'une liste d'id de bar de la même longeur que celle des user \n",
    "    liste_place.append(random.choice(place_id_list))#choix d'un bar random\n",
    "\n",
    "\n",
    "dico_user_bar={'user_id':liste_user,'place_id':liste_place}\n",
    "favorite_for_new_user = pd.DataFrame(dico_user_bar)#creation d'un dataframe des nouvelle rellation user bar\n",
    "favorite_for_new_user\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "maintenant nous pouvons recollé les vrais favorie avec nos favoris artificielle "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id            15285\n",
       "place_id       7321\n",
       "user_id       45480\n",
       "created_at    15268\n",
       "dtype: int64"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "favorit_generalle=pd.concat([df_favorite,favorite_for_new_user])\n",
    "favorit_generalle.nunique()\n",
    "#on remarque que certaint bar ne ce voit attribué personne ce qui posse probleme"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ici on fais le chemins inverse, on determine qu'elle bar n'a pas recue de favoris par des user  et on leur en attribue une mais que sur les user qui n'en n'avais pas initiallement pour ne pas alteré la data des user en possedant "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "user_id     28\n",
       "place_id    28\n",
       "dtype: int64"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bar_sans_favoris=favorit_generalle.drop_duplicates(subset='place_id')\n",
    "bar_sans_favoris=bar_sans_favoris['place_id']#liste des bar possedant au moins une rellations\n",
    "\n",
    "\n",
    "place_without_favoris = place.merge(\n",
    "    bar_sans_favoris,how='outer',left_on='id',right_on='place_id',indicator=True\n",
    ")\n",
    "indexNames=place_without_favoris[place_without_favoris['_merge'] == 'both'].index\n",
    "place_without_favoris.drop(indexNames , inplace=True)\n",
    "#ici on utilise la meme technique que pour user decrite un peut plus haut pour identifier\n",
    "#les bar sans favoris \n",
    "\n",
    "place_without_favoris=place_without_favoris[['id']]\n",
    "\n",
    "#mise au format de list des user sans favoris \n",
    "user_id_list=df_user_without_favoris.user_id.to_list()\n",
    "\n",
    "#on genere une rellation aleatoire pour les bar qui sont encore non liées\n",
    "place_without_favoris=place_without_favoris.id.to_list()\n",
    "\n",
    "list_user=[]\n",
    "#on genere une rellation aleatoire pour les bar qui sont encore non liées \n",
    "# mais seulement avec les user qui n'en non pas initiallement\n",
    "for i in place_without_favoris:\n",
    "    list_user.append(random.choice(user_id_list))\n",
    "\n",
    "dickos={'user_id':list_user,'place_id':place_without_favoris}\n",
    "favorite_for_place_alone = pd.DataFrame(dickos)\n",
    "\n",
    "#cette ligne permet de verifier qu'on a bien ajouté le nombre de bar restant vue precedement \n",
    "favorite_for_place_alone.nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "et on assemble tous ces favoris crée au favoris generé"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id            15285\n",
       "place_id       7349\n",
       "user_id       45480\n",
       "created_at    15268\n",
       "dtype: int64"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "favorite=pd.concat([favorit_generalle,favorite_for_place_alone])#simple concat\n",
    "favorite.nunique()#affiche le nombre de user et place differente (crée & rélle) et qu'il \n",
    "#correspond a nos table user et place en longeur "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ici on crée le detaframe globale qui stockera les feature, le poid, et les rellation entre les user et les bar "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "# on crée des id unique pour chaque rellation favoris entre les user et place qui \n",
    "# respecte les besoin de lightfm \n",
    "favorite_for_merge=favorite[['user_id',\"place_id\"]]\n",
    "favorite_for_merge = generate_int_id(favorite_for_merge,'favorite_id_light')\n",
    "\n",
    "# on merge place_type avec place_place_type = type_for_merge\n",
    "type_for_merge=place_type.merge(\n",
    "    df_place_place_type,how='inner',right_on='type_id',left_on='id'\n",
    ")\n",
    "\n",
    "# on merge place avec type for merge pour assossier les item aux places=place_for_merge\n",
    "type_for_merge=type_for_merge.drop([\"id\",'type_id'],axis=1)\n",
    "\n",
    "place_for_merge=place.merge(\n",
    "    type_for_merge,how='left',left_on='id',right_on='place_id'\n",
    ")\n",
    "\n",
    "# on merge place_for_merge avec les user\n",
    "df_merge=user.merge(\n",
    "    favorite_for_merge,how=\"inner\",left_on='user_id',right_on='user_id'\n",
    ")\n",
    "#on merge finalement toute nos donné ensemble\n",
    "df_merge=df_merge.merge(\n",
    "    place_for_merge,how='left',left_on='place_id',right_on='id'\n",
    ")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ici on prepare les item necessaire pour lightfm en ce bassant sur les type des bar que les user on en favoris ou autre \n",
    "\n",
    "cela permet le fonctionement de type content-based filtering de notre model\n",
    "\n",
    "et on crée une seule ligne par utilisateur avec les type des bar qu'il a frequenté en decoupant ces dernier un par un pour l'analyse textuel futur du model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "#on recupere de notre df_merge les id light des user et name qui est le type des bar \n",
    "# avec les qu'elle ils on interagis \n",
    "user_id_and_placetype=df_merge[['user_id_light','name']]\n",
    "\n",
    "user_id_and_placetype=user_id_and_placetype.dropna()#on drop les na par securité \n",
    "\n",
    "#on regroupe les type des bar fréquente par chaque user en une seule ligne\n",
    "# en les regroupant un a un \n",
    "user_id_and_placetype=user_id_and_placetype.groupby(\n",
    "    ['user_id_light'])['name'].apply(\n",
    "        ','.join).reset_index()\n",
    "user_id_and_placetype['name'] = (\n",
    "    user_id_and_placetype['name'].str.split(',').apply(set).str.join(','))\n",
    "\n",
    "#on regroupe cela avec les infos que l'on a sur chaque utilisateur pour crée notre  \n",
    "# dataframe qui possede une ligne par user \n",
    "df_user_ready=user.merge(\n",
    "    user_id_and_placetype,how='left',on='user_id_light'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>firebase_uid</th>\n",
       "      <th>user_id_light</th>\n",
       "      <th>name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>31280</td>\n",
       "      <td>zzzZClWPVSQ22uT2SqQqQQfSPon2</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>33287</td>\n",
       "      <td>ZZzYwUhcuTN7WUlKTNVJ0El7Gz83</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>29924</td>\n",
       "      <td>zZZMZBYZKXP3ClI83zvehUXXXsp2</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11040</td>\n",
       "      <td>ZzZ4AF9HvmaWo3ssjW3vAmgEacj1</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>32661</td>\n",
       "      <td>zzxJ4S3MRxVDxcZ71UWQv7qfUG92</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45475</th>\n",
       "      <td>16737</td>\n",
       "      <td>00KjtvKZG3ahSKyCt3AyRyTAesG3</td>\n",
       "      <td>45475</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45476</th>\n",
       "      <td>31535</td>\n",
       "      <td>00FyNO18CYSV8sLQgbpKH0kQRmP2</td>\n",
       "      <td>45476</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45477</th>\n",
       "      <td>39028</td>\n",
       "      <td>00e24es9Rse3DSsByF9kgR8TPHD3</td>\n",
       "      <td>45477</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45478</th>\n",
       "      <td>40048</td>\n",
       "      <td>00AUdltem0aniOvFw8iRpCgO9Fo1</td>\n",
       "      <td>45478</td>\n",
       "      <td>Bar LGBTQI+</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45479</th>\n",
       "      <td>26641</td>\n",
       "      <td>005zUjouOgaUICI0gNaTOYAdX082</td>\n",
       "      <td>45479</td>\n",
       "      <td>Bar d'hôtel</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>45480 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       user_id                  firebase_uid  user_id_light         name\n",
       "0        31280  zzzZClWPVSQ22uT2SqQqQQfSPon2              0          NaN\n",
       "1        33287  ZZzYwUhcuTN7WUlKTNVJ0El7Gz83              1          NaN\n",
       "2        29924  zZZMZBYZKXP3ClI83zvehUXXXsp2              2          NaN\n",
       "3        11040  ZzZ4AF9HvmaWo3ssjW3vAmgEacj1              3          NaN\n",
       "4        32661  zzxJ4S3MRxVDxcZ71UWQv7qfUG92              4          NaN\n",
       "...        ...                           ...            ...          ...\n",
       "45475    16737  00KjtvKZG3ahSKyCt3AyRyTAesG3          45475          NaN\n",
       "45476    31535  00FyNO18CYSV8sLQgbpKH0kQRmP2          45476          NaN\n",
       "45477    39028  00e24es9Rse3DSsByF9kgR8TPHD3          45477          NaN\n",
       "45478    40048  00AUdltem0aniOvFw8iRpCgO9Fo1          45478  Bar LGBTQI+\n",
       "45479    26641  005zUjouOgaUICI0gNaTOYAdX082          45479  Bar d'hôtel\n",
       "\n",
       "[45480 rows x 4 columns]"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_user_ready"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "comme pour les user juste avant nous reorganison comment sont stocker les type des bar avec en sortie une seul ligne par bar et s'est type rangé dans une liste"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "place_for_item= place_for_merge\n",
    "place_for_item['name']=place_for_item['name'].fillna('No Tag')#pour evité des probleme on remplace les type manquant par no tag \n",
    "\n",
    "place_for_item=place_for_item.groupby(\n",
    "    ['place_id_light'])['name'].apply(\n",
    "        ','.join).reset_index()\n",
    "place_for_item['name'] = (\n",
    "    place_for_item['name'].str.split(',').apply(set).str.join(','))\n",
    "\n",
    "#on regroupe toute les infos des bar ici\n",
    "df_place_ready = place.merge(\n",
    "    place_for_item,how='left',on='place_id_light'\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "on crée les route interne pour le mapping de lightfm partie critique car si un user ou un bar venais a manqué cela crée une discontinuité pour lightfm qui nous retournerais une erreur "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "#on genere les list de feature pour le mapping de lightfm\n",
    "user_feature_list = generate_feature_list(\n",
    "    df_user_ready,['name']\n",
    ")\n",
    "place_feature_list = generate_feature_list(\n",
    "    df_place_ready,['name']\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "les feature sont les type des bar \n",
    "on les associe a chaque user en fonction de sont id light\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creation des feature qui vont allimenté notre modele\n",
    "df_user_ready['user_feature2']=create_features(\n",
    "    df_user_ready,['name'],'user_id_light'\n",
    ")\n",
    "\n",
    "df_place_ready['place_feature'] = create_features(\n",
    "    df_place_ready,['name'],'place_id_light'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_merge['total_weights']=random.randint(0,5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ici on definie les variable de notre dataset\n",
    "pour cela on donne l'id unique de chaque user et item(bar/place)\n",
    "mais aussi les feature tous cela va crée le mapping interne pour notre modele"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = Dataset()\n",
    "dataset.fit(\n",
    "    set(df_user_ready['user_id_light']),\n",
    "    set(df_place_ready['place_id_light']), \n",
    "    user_features=user_feature_list,\n",
    "    item_features=place_feature_list)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "maintenant on crée la matrice des interaction entre les user et les place\n",
    "pour cela on passe les id de ces dernier comme des tuple \n",
    "\n",
    "et avec cela on utilise la fonction native de lightfm pour crée notre matrice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merge['bar_user_id_tuple']=list(zip(\n",
    "    df_merge.user_id_light,df_merge.place_id_light\n",
    "))\n",
    "interactions,weights=dataset.build_interactions(\n",
    "    df_merge['bar_user_id_tuple']\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ici on fais construire les feature des bar et user d'une facon que lightfm comprend\n",
    "pour cela on utilise la fonction integre de lightfm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_feature = dataset.build_user_features(\n",
    "    df_user_ready['user_feature2']\n",
    ")\n",
    "place_feature = dataset.build_item_features(\n",
    "    df_place_ready['place_feature']\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ici on crée notre model avec c'est multiple parametre puis on l'entraine en lui donnant toute les liste et dataframe crée precedement \n",
    "\n",
    "\n",
    "attention il faut ajusté le 'num_threads' au nombre de core de votre ordinateur"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 100%|██████████| 7/7 [00:06<00:00,  1.14it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<lightfm.lightfm.LightFM at 0x13aa29a00>"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = LightFM(\n",
    "    no_components=300,\n",
    "    learning_rate=0.02,\n",
    "    loss='warp',\n",
    "    random_state=2019)\n",
    "\n",
    "model.fit(\n",
    "    interactions,\n",
    "    user_features=user_feature,\n",
    "    item_features=place_feature,\n",
    "    sample_weight=weights,\n",
    "    epochs=7, num_threads=8, verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "on calcule le score AUC ici et obtient 0,75 ce qui n'est pas mauvais au vue du manque de data de notre situation \n",
    "\n",
    "a noté que avec le temps la db de schlouk map va grandir et donc permettre a notre modele de devenir meilleur "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8407551"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calculate_auc_score(model,interactions,place_feature,user_feature)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "on extrait les id des user bar et item du mapping de notre dataset pour pouvoir les ciblé pendant nos prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_id_map, user_feature_map, item_id_map, item_feature_map = dataset.mapping()\n",
    "\n",
    "n_users, n_items = interactions.shape# permet d'avoir la taille de notre dataset et \n",
    "#ne pas le depassé pendant les prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>score</th>\n",
       "      <th>id</th>\n",
       "      <th>is_closed</th>\n",
       "      <th>is_published</th>\n",
       "      <th>has_offers</th>\n",
       "      <th>has_food</th>\n",
       "      <th>has_terrace</th>\n",
       "      <th>slug</th>\n",
       "      <th>city_id</th>\n",
       "      <th>place_id_light</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3863</th>\n",
       "      <td>3863</td>\n",
       "      <td>0.511049</td>\n",
       "      <td>4032</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>le-viaduc</td>\n",
       "      <td>3</td>\n",
       "      <td>3863</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3488</th>\n",
       "      <td>3488</td>\n",
       "      <td>0.395485</td>\n",
       "      <td>3655</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>le-montebello</td>\n",
       "      <td>3</td>\n",
       "      <td>3488</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3823</th>\n",
       "      <td>3823</td>\n",
       "      <td>0.279922</td>\n",
       "      <td>3992</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>cabana-beach</td>\n",
       "      <td>3</td>\n",
       "      <td>3823</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3528</th>\n",
       "      <td>3528</td>\n",
       "      <td>0.263438</td>\n",
       "      <td>3696</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>team-brothers</td>\n",
       "      <td>3</td>\n",
       "      <td>3528</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>512</th>\n",
       "      <td>512</td>\n",
       "      <td>0.248808</td>\n",
       "      <td>520</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>dalea</td>\n",
       "      <td>3</td>\n",
       "      <td>512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>401</th>\n",
       "      <td>401</td>\n",
       "      <td>-0.620456</td>\n",
       "      <td>408</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>au-fut-et-a-mesure-1</td>\n",
       "      <td>3</td>\n",
       "      <td>401</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>833</th>\n",
       "      <td>833</td>\n",
       "      <td>-0.647229</td>\n",
       "      <td>848</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>lizard-lounge</td>\n",
       "      <td>3</td>\n",
       "      <td>833</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3520</th>\n",
       "      <td>3520</td>\n",
       "      <td>-0.651768</td>\n",
       "      <td>3687</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>cicchetti-1</td>\n",
       "      <td>3</td>\n",
       "      <td>3520</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>430</th>\n",
       "      <td>430</td>\n",
       "      <td>-0.652812</td>\n",
       "      <td>437</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>le-onze</td>\n",
       "      <td>3</td>\n",
       "      <td>430</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7088</th>\n",
       "      <td>7088</td>\n",
       "      <td>-0.721018</td>\n",
       "      <td>7271</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>val-cafe</td>\n",
       "      <td>3</td>\n",
       "      <td>7088</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1156 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      index     score    id is_closed is_published has_offers has_food  \\\n",
       "3863   3863  0.511049  4032         0            1          0      1.0   \n",
       "3488   3488  0.395485  3655         0            1          0      1.0   \n",
       "3823   3823  0.279922  3992         0            1          0      1.0   \n",
       "3528   3528  0.263438  3696         0            1          0      NaN   \n",
       "512     512  0.248808   520         0            1          0      1.0   \n",
       "...     ...       ...   ...       ...          ...        ...      ...   \n",
       "401     401 -0.620456   408         0            1          0      NaN   \n",
       "833     833 -0.647229   848         0            1          0      1.0   \n",
       "3520   3520 -0.651768  3687         0            1          0      1.0   \n",
       "430     430 -0.652812   437         0            1          0      NaN   \n",
       "7088   7088 -0.721018  7271         0            1          0      NaN   \n",
       "\n",
       "     has_terrace                  slug city_id  place_id_light  \n",
       "3863         1.0             le-viaduc       3            3863  \n",
       "3488         1.0         le-montebello       3            3488  \n",
       "3823         1.0          cabana-beach       3            3823  \n",
       "3528         NaN         team-brothers       3            3528  \n",
       "512          1.0                 dalea       3             512  \n",
       "...          ...                   ...     ...             ...  \n",
       "401          NaN  au-fut-et-a-mesure-1       3             401  \n",
       "833          NaN         lizard-lounge       3             833  \n",
       "3520         1.0           cicchetti-1       3            3520  \n",
       "430          NaN               le-onze       3             430  \n",
       "7088         1.0              val-cafe       3            7088  \n",
       "\n",
       "[1156 rows x 11 columns]"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recommandation_for_user_by_city(2,3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "notre fonction definie dans le bloc des fonction qui retourne les bar trié par pertinance pour un user en filtrant selon la ville et les bar qu'il connais deja "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "131.82801504200006\n"
     ]
    }
   ],
   "source": [
    "b=time.perf_counter()\n",
    "print(b-a)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "c4830847cf3f18ede4a86915073450203c23cff2bb8003fe251664fa9487d16d"
  },
  "kernelspec": {
   "display_name": "Python 3.9.12 ('py3k')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
